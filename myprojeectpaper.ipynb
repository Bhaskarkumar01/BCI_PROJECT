{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4784f3af",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-12T14:27:49.355778Z",
     "iopub.status.busy": "2026-02-12T14:27:49.355222Z",
     "iopub.status.idle": "2026-02-12T14:27:49.362011Z",
     "shell.execute_reply": "2026-02-12T14:27:49.361435Z"
    },
    "papermill": {
     "duration": 0.012801,
     "end_time": "2026-02-12T14:27:49.363483",
     "exception": false,
     "start_time": "2026-02-12T14:27:49.350682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70d22b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:27:49.369599Z",
     "iopub.status.busy": "2026-02-12T14:27:49.369407Z",
     "iopub.status.idle": "2026-02-12T14:27:49.710783Z",
     "shell.execute_reply": "2026-02-12T14:27:49.709960Z"
    },
    "papermill": {
     "duration": 0.346353,
     "end_time": "2026-02-12T14:27:49.712573",
     "exception": false,
     "start_time": "2026-02-12T14:27:49.366220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p /kaggle/working/project/data\n",
    "!mkdir -p /kaggle/working/project/model\n",
    "!mkdir -p /kaggle/working/project/results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53434450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:27:49.719113Z",
     "iopub.status.busy": "2026-02-12T14:27:49.718821Z",
     "iopub.status.idle": "2026-02-12T14:27:49.725453Z",
     "shell.execute_reply": "2026-02-12T14:27:49.724718Z"
    },
    "papermill": {
     "duration": 0.011586,
     "end_time": "2026-02-12T14:27:49.726804",
     "exception": false,
     "start_time": "2026-02-12T14:27:49.715218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/project/data/data_loader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/project/data/data_loader.py\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import mne\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "class BCIV2aDataset(Dataset):\n",
    "    def __init__(self, gdf_path, mat_path=None):\n",
    "\n",
    "        print(f\"Loading {gdf_path}\")\n",
    "\n",
    "        raw = mne.io.read_raw_gdf(gdf_path, preload=True, verbose=False)\n",
    "        # raw.pick(\"eeg\")\n",
    "        # Keep only first 22 EEG channels (exclude EOG) \n",
    "        eeg_channels = raw.ch_names[:22]\n",
    "        raw.pick_channels(eeg_channels)\n",
    "\n",
    "        raw.filter(8., 30., fir_design=\"firwin\", verbose=False)\n",
    "\n",
    "        events, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "        # -------- TRAINING SESSION --------\n",
    "        if mat_path is None:\n",
    "\n",
    "            mi_event_names = ['769', '770', '771', '772']\n",
    "\n",
    "            valid_event_id = {\n",
    "                key: event_dict[key]\n",
    "                for key in mi_event_names\n",
    "                if key in event_dict\n",
    "            }\n",
    "\n",
    "            epochs = mne.Epochs(\n",
    "                raw,\n",
    "                events,\n",
    "                event_id=valid_event_id,\n",
    "                tmin=0.5,\n",
    "                tmax=2.5,\n",
    "                baseline=None,\n",
    "                preload=True,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            self.data = epochs.get_data()\n",
    "            # self.labels = epochs.events[:, -1] - 1\n",
    "            # Map event IDs to 0â€“3\n",
    "            label_map = {\n",
    "            valid_event_id['769']: 0,\n",
    "            valid_event_id['770']: 1,\n",
    "            valid_event_id['771']: 2,\n",
    "            valid_event_id['772']: 3\n",
    "            }\n",
    "\n",
    "            self.labels = np.array([label_map[e] for e in epochs.events[:, -1]])\n",
    "\n",
    "\n",
    "        # -------- EVALUATION SESSION --------\n",
    "        else:\n",
    "\n",
    "            # Use event 783 for evaluation session\n",
    "            if '783' not in event_dict:\n",
    "                raise ValueError(\"Event 783 not found in E file.\")\n",
    "\n",
    "            eval_event_id = {'783': event_dict['783']}\n",
    "\n",
    "            epochs = mne.Epochs(\n",
    "                raw,\n",
    "                events,\n",
    "                event_id=eval_event_id,\n",
    "                tmin=0.5,\n",
    "                tmax=2.5,\n",
    "                baseline=None,\n",
    "                preload=True,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            self.data = epochs.get_data()\n",
    "\n",
    "            # Load true labels from .mat\n",
    "            mat = sio.loadmat(mat_path)\n",
    "            self.labels = mat[\"classlabel\"].squeeze().astype(int) - 1\n",
    "\n",
    "        print(f\"Loaded {len(self.data)} trials\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "    #     y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "    #     return x, y\n",
    "    def __getitem__(self, idx):\n",
    "          x = self.data[idx]  # (C, T)\n",
    "\n",
    "          # Trial-wise normalization\n",
    "          x = (x - np.mean(x, axis=1, keepdims=True)) / (np.std(x, axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "          x = torch.tensor(x, dtype=torch.float32)\n",
    "          y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "          return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1c702d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:27:49.733136Z",
     "iopub.status.busy": "2026-02-12T14:27:49.732695Z",
     "iopub.status.idle": "2026-02-12T14:27:54.354748Z",
     "shell.execute_reply": "2026-02-12T14:27:54.353721Z"
    },
    "papermill": {
     "duration": 4.627314,
     "end_time": "2026-02-12T14:27:54.356591",
     "exception": false,
     "start_time": "2026-02-12T14:27:49.729277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/datasets/bhaskarkumar01/bciciv-2a /kaggle/working/project/data/BCICIV_2a_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6df0d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:27:54.363811Z",
     "iopub.status.busy": "2026-02-12T14:27:54.363108Z",
     "iopub.status.idle": "2026-02-12T14:28:00.997011Z",
     "shell.execute_reply": "2026-02-12T14:28:00.996233Z"
    },
    "papermill": {
     "duration": 6.639435,
     "end_time": "2026-02-12T14:28:00.998809",
     "exception": false,
     "start_time": "2026-02-12T14:27:54.359374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python /kaggle/working/project/data/data_loader.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cb70360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:28:01.006319Z",
     "iopub.status.busy": "2026-02-12T14:28:01.005636Z",
     "iopub.status.idle": "2026-02-12T14:28:01.010814Z",
     "shell.execute_reply": "2026-02-12T14:28:01.010067Z"
    },
    "papermill": {
     "duration": 0.010666,
     "end_time": "2026-02-12T14:28:01.012377",
     "exception": false,
     "start_time": "2026-02-12T14:28:01.001711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/project/data/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/project/data/utils.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    _, pred = torch.max(preds, 1)\n",
    "    return (pred == labels).float().mean().item()\n",
    "\n",
    "def bandpass_filter(data, low=8, high=30, fs=250, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low /= nyq\n",
    "    high /= nyq\n",
    "    b, a = butter(order, [low, high], btype=\"band\")\n",
    "    return lfilter(b, a, data, axis=-1)\n",
    "\n",
    "def normalize(trial):\n",
    "    mean = trial.mean(axis=-1, keepdims=True)\n",
    "    std = trial.std(axis=-1, keepdims=True) + 1e-6\n",
    "    return (trial - mean) / std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe232ba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:28:01.018541Z",
     "iopub.status.busy": "2026-02-12T14:28:01.018304Z",
     "iopub.status.idle": "2026-02-12T14:28:01.022949Z",
     "shell.execute_reply": "2026-02-12T14:28:01.022344Z"
    },
    "papermill": {
     "duration": 0.009292,
     "end_time": "2026-02-12T14:28:01.024308",
     "exception": false,
     "start_time": "2026-02-12T14:28:01.015016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/project/model/multiscale_cnn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/project/model/multiscale_cnn.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiScaleCNN(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels, 32, kernel_size=(1,3), padding=(0,1))\n",
    "        self.conv5 = nn.Conv2d(in_channels, 32, kernel_size=(1,5), padding=(0,2))\n",
    "        self.conv7 = nn.Conv2d(in_channels, 32, kernel_size=(1,7), padding=(0,3))\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(96)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, 1, T)\n",
    "        f1 = F.relu(self.conv3(x))\n",
    "        f2 = F.relu(self.conv5(x))\n",
    "        f3 = F.relu(self.conv7(x))\n",
    "\n",
    "        out = torch.cat([f1, f2, f3], dim=1)\n",
    "        out = self.bn(out)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce81541a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:28:01.030885Z",
     "iopub.status.busy": "2026-02-12T14:28:01.030482Z",
     "iopub.status.idle": "2026-02-12T14:28:01.034907Z",
     "shell.execute_reply": "2026-02-12T14:28:01.034100Z"
    },
    "papermill": {
     "duration": 0.009481,
     "end_time": "2026-02-12T14:28:01.036413",
     "exception": false,
     "start_time": "2026-02-12T14:28:01.026932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/project/model/transformer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/project/model/transformer.py\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=4,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(layer, num_layers=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, D)\n",
    "        return self.encoder(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ec2170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:28:01.043068Z",
     "iopub.status.busy": "2026-02-12T14:28:01.042558Z",
     "iopub.status.idle": "2026-02-12T14:28:01.047054Z",
     "shell.execute_reply": "2026-02-12T14:28:01.046488Z"
    },
    "papermill": {
     "duration": 0.009141,
     "end_time": "2026-02-12T14:28:01.048298",
     "exception": false,
     "start_time": "2026-02-12T14:28:01.039157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/project/model/cl_mst.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/project/model/cl_mst.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model.multiscale_cnn import MultiScaleCNN\n",
    "from model.transformer import TransformerEncoder\n",
    "\n",
    "class CL_MST(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mscnn = MultiScaleCNN(in_channels)\n",
    "        self.transformer = TransformerEncoder(embed_dim=96)\n",
    "\n",
    "        self.classifier = nn.Linear(96, num_classes)\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(96, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        x = x.unsqueeze(2)               # (B, C, 1, T)\n",
    "        feats = self.mscnn(x)            # (B, 96, 1, T)\n",
    "        feats = feats.squeeze(2)         # (B, 96, T)\n",
    "        feats = feats.permute(0, 2, 1)   # (B, T, 96)\n",
    "\n",
    "        encoded = self.transformer(feats)\n",
    "        pooled = encoded.mean(dim=1)\n",
    "\n",
    "        logits = self.classifier(pooled)\n",
    "        proj = self.projection_head(pooled)\n",
    "\n",
    "        return logits, proj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af89c8ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:28:01.054754Z",
     "iopub.status.busy": "2026-02-12T14:28:01.054565Z",
     "iopub.status.idle": "2026-02-12T14:28:01.060296Z",
     "shell.execute_reply": "2026-02-12T14:28:01.059577Z"
    },
    "papermill": {
     "duration": 0.010686,
     "end_time": "2026-02-12T14:28:01.061595",
     "exception": false,
     "start_time": "2026-02-12T14:28:01.050909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/project/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/project/train.py\n",
    "\n",
    "\n",
    "\n",
    "# train.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "from data.data_loader  import BCIV2aDataset\n",
    "from model.cl_mst import CL_MST  # your model\n",
    "\n",
    "from loss import supervised_contrastive_loss\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIR = \"/kaggle/input/datasets/bhaskarkumar01/bciciv-2a\"\n",
    "\n",
    "\n",
    "def load_all_subjects():\n",
    "    train_datasets = []\n",
    "    test_datasets = []\n",
    "\n",
    "    for i in range(1, 10):\n",
    "        subject = f\"A0{i}\"\n",
    "\n",
    "        train_gdf = os.path.join(DATA_DIR, f\"{subject}T.gdf\")\n",
    "        test_gdf = os.path.join(DATA_DIR, f\"{subject}E.gdf\")\n",
    "        test_mat = os.path.join(DATA_DIR, f\"{subject}E.mat\")\n",
    "\n",
    "        train_datasets.append(BCIV2aDataset(train_gdf))\n",
    "        test_datasets.append(BCIV2aDataset(test_gdf, test_mat))\n",
    "\n",
    "    train_dataset = ConcatDataset(train_datasets)\n",
    "    test_dataset = ConcatDataset(test_datasets)\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "# def train_model(model, train_loader, criterion, optimizer):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "\n",
    "#     for x, y in train_loader:\n",
    "#         x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         # outputs = model(x)\n",
    "#         # loss = criterion(outputs, y)\n",
    "#         logits, _ = model(x)\n",
    "#         loss = criterion(logits, y)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     return total_loss / len(train_loader)\n",
    "\n",
    "def train_model(model, train_loader, ce_loss, optimizer, lambda_c=0.2):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, proj = model(x)\n",
    "\n",
    "        loss_ce = ce_loss(logits, y)\n",
    "        loss_con = supervised_contrastive_loss(proj, y)\n",
    "\n",
    "        loss = loss_ce + lambda_c * loss_con\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(DEVICE)\n",
    "\n",
    "            # outputs = model(x)\n",
    "            # preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            logits, _ = model(x)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(y.numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return acc, kappa, cm\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Loading datasets...\")\n",
    "\n",
    "    train_dataset, test_dataset = load_all_subjects()\n",
    "\n",
    "    print(\"Train samples:\", len(train_dataset))\n",
    "    print(\"Test samples:\", len(test_dataset))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # model = CL_MST().to(DEVICE)\n",
    "    model = CL_MST(in_channels=22, num_classes=4).to(DEVICE)\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    EPOCHS = 50\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # loss = train_model(model, train_loader, criterion, optimizer)\n",
    "        loss = train_model(model, train_loader, criterion, optimizer, lambda_c=0.2)\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {loss:.4f}\")\n",
    "\n",
    "    print(\"\\nEvaluating on E session...\")\n",
    "\n",
    "    acc, kappa, cm = evaluate_model(model, test_loader)\n",
    "\n",
    "    print(\"\\n===== FINAL RESULTS =====\")\n",
    "    print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "    print(f\"Cohen Kappa: {kappa:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a19e97dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:28:01.068065Z",
     "iopub.status.busy": "2026-02-12T14:28:01.067827Z",
     "iopub.status.idle": "2026-02-12T14:28:01.072473Z",
     "shell.execute_reply": "2026-02-12T14:28:01.071646Z"
    },
    "papermill": {
     "duration": 0.009468,
     "end_time": "2026-02-12T14:28:01.073821",
     "exception": false,
     "start_time": "2026-02-12T14:28:01.064353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/project/loss.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/project/loss.py\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def contrastive_loss(z1, z2):\n",
    "#     z1 = F.normalize(z1, dim=1)\n",
    "#     z2 = F.normalize(z2, dim=1)\n",
    "#     return 1 - F.cosine_similarity(z1, z2).mean()\n",
    "\n",
    "\n",
    "\n",
    "# loss.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def supervised_contrastive_loss(features, labels, temperature=0.07):\n",
    "    \"\"\"\n",
    "    features: (B, D)\n",
    "    labels: (B,)\n",
    "    \"\"\"\n",
    "\n",
    "    device = features.device\n",
    "    features = F.normalize(features, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(features, features.T) / temperature\n",
    "\n",
    "    labels = labels.contiguous().view(-1, 1)\n",
    "    mask = torch.eq(labels, labels.T).float().to(device)\n",
    "\n",
    "    logits_mask = torch.ones_like(mask) - torch.eye(mask.shape[0]).to(device)\n",
    "    mask = mask * logits_mask\n",
    "\n",
    "    exp_sim = torch.exp(similarity_matrix) * logits_mask\n",
    "\n",
    "    log_prob = similarity_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "    mean_log_prob_pos = (mask * log_prob).sum(dim=1) / (mask.sum(dim=1) + 1e-8)\n",
    "\n",
    "    loss = -mean_log_prob_pos.mean()\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09b0c331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:28:01.080562Z",
     "iopub.status.busy": "2026-02-12T14:28:01.079888Z",
     "iopub.status.idle": "2026-02-12T14:28:01.084497Z",
     "shell.execute_reply": "2026-02-12T14:28:01.083954Z"
    },
    "papermill": {
     "duration": 0.009286,
     "end_time": "2026-02-12T14:28:01.085750",
     "exception": false,
     "start_time": "2026-02-12T14:28:01.076464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/project/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/project/utils.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    _, pred = torch.max(preds, 1)\n",
    "    return (pred == labels).float().mean().item()\n",
    "\n",
    "def bandpass_filter(data, low=8, high=30, fs=250, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low /= nyq\n",
    "    high /= nyq\n",
    "    b, a = butter(order, [low, high], btype=\"band\")\n",
    "    return lfilter(b, a, data, axis=-1)\n",
    "\n",
    "def normalize(trial):\n",
    "    mean = trial.mean(axis=-1, keepdims=True)\n",
    "    std = trial.std(axis=-1, keepdims=True) + 1e-6\n",
    "    return (trial - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729fc7f7",
   "metadata": {
    "papermill": {
     "duration": 0.002827,
     "end_time": "2026-02-12T14:28:01.091321",
     "exception": false,
     "start_time": "2026-02-12T14:28:01.088494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50099311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:28:01.098016Z",
     "iopub.status.busy": "2026-02-12T14:28:01.097585Z",
     "iopub.status.idle": "2026-02-12T14:28:01.100731Z",
     "shell.execute_reply": "2026-02-12T14:28:01.100075Z"
    },
    "papermill": {
     "duration": 0.007984,
     "end_time": "2026-02-12T14:28:01.102107",
     "exception": false,
     "start_time": "2026-02-12T14:28:01.094123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/kaggle/working/project\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f0f78d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T14:28:01.108977Z",
     "iopub.status.busy": "2026-02-12T14:28:01.108541Z",
     "iopub.status.idle": "2026-02-12T14:31:34.463487Z",
     "shell.execute_reply": "2026-02-12T14:31:34.462769Z"
    },
    "papermill": {
     "duration": 213.360341,
     "end_time": "2026-02-12T14:31:34.465242",
     "exception": false,
     "start_time": "2026-02-12T14:28:01.104901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A01T.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A01E.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A02T.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A02E.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A03T.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A03E.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A04T.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A04E.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A05T.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A05E.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A06T.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A06E.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A07T.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A07E.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A08T.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A08E.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A09T.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\r\n",
      "Loaded 288 trials\r\n",
      "Loading /kaggle/input/datasets/bhaskarkumar01/bciciv-2a/A09E.gdf\r\n",
      "/usr/lib/python3.12/contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\r\n",
      "  next(self.gen)\r\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\r\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\r\n",
      "Loaded 288 trials\r\n",
      "Train samples: 2592\r\n",
      "Test samples: 2592\r\n",
      "Epoch [1/50] Loss: 2.0671\r\n",
      "Epoch [2/50] Loss: 1.9620\r\n",
      "Epoch [3/50] Loss: 1.9274\r\n",
      "Epoch [4/50] Loss: 1.8934\r\n",
      "Epoch [5/50] Loss: 1.8727\r\n",
      "Epoch [6/50] Loss: 1.8301\r\n",
      "Epoch [7/50] Loss: 1.8222\r\n",
      "Epoch [8/50] Loss: 1.7853\r\n",
      "Epoch [9/50] Loss: 1.7642\r\n",
      "Epoch [10/50] Loss: 1.7727\r\n",
      "Epoch [11/50] Loss: 1.7367\r\n",
      "Epoch [12/50] Loss: 1.7170\r\n",
      "Epoch [13/50] Loss: 1.6910\r\n",
      "Epoch [14/50] Loss: 1.6737\r\n",
      "Epoch [15/50] Loss: 1.6574\r\n",
      "Epoch [16/50] Loss: 1.6448\r\n",
      "Epoch [17/50] Loss: 1.6284\r\n",
      "Epoch [18/50] Loss: 1.5973\r\n",
      "Epoch [19/50] Loss: 1.5829\r\n",
      "Epoch [20/50] Loss: 1.5822\r\n",
      "Epoch [21/50] Loss: 1.5858\r\n",
      "Epoch [22/50] Loss: 1.5447\r\n",
      "Epoch [23/50] Loss: 1.5393\r\n",
      "Epoch [24/50] Loss: 1.5294\r\n",
      "Epoch [25/50] Loss: 1.4964\r\n",
      "Epoch [26/50] Loss: 1.4852\r\n",
      "Epoch [27/50] Loss: 1.4793\r\n",
      "Epoch [28/50] Loss: 1.4735\r\n",
      "Epoch [29/50] Loss: 1.4150\r\n",
      "Epoch [30/50] Loss: 1.4137\r\n",
      "Epoch [31/50] Loss: 1.3994\r\n",
      "Epoch [32/50] Loss: 1.3912\r\n",
      "Epoch [33/50] Loss: 1.3755\r\n",
      "Epoch [34/50] Loss: 1.3435\r\n",
      "Epoch [35/50] Loss: 1.3173\r\n",
      "Epoch [36/50] Loss: 1.3123\r\n",
      "Epoch [37/50] Loss: 1.2955\r\n",
      "Epoch [38/50] Loss: 1.2978\r\n",
      "Epoch [39/50] Loss: 1.2544\r\n",
      "Epoch [40/50] Loss: 1.2787\r\n",
      "Epoch [41/50] Loss: 1.2070\r\n",
      "Epoch [42/50] Loss: 1.2128\r\n",
      "Epoch [43/50] Loss: 1.1779\r\n",
      "Epoch [44/50] Loss: 1.1993\r\n",
      "Epoch [45/50] Loss: 1.1594\r\n",
      "Epoch [46/50] Loss: 1.1223\r\n",
      "Epoch [47/50] Loss: 1.1283\r\n",
      "Epoch [48/50] Loss: 1.0891\r\n",
      "Epoch [49/50] Loss: 1.0508\r\n",
      "Epoch [50/50] Loss: 1.0653\r\n",
      "\r\n",
      "Evaluating on E session...\r\n",
      "\r\n",
      "===== FINAL RESULTS =====\r\n",
      "Accuracy: 51.81%\r\n",
      "Cohen Kappa: 0.3575\r\n",
      "Confusion Matrix:\r\n",
      "[[436 142  53  17]\r\n",
      " [135 431  50  32]\r\n",
      " [142 156 199 151]\r\n",
      " [142 136  93 277]]\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python  /kaggle/working/project/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633a814",
   "metadata": {
    "papermill": {
     "duration": 0.006384,
     "end_time": "2026-02-12T14:31:34.478554",
     "exception": false,
     "start_time": "2026-02-12T14:31:34.472170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9453807,
     "sourceId": 14787799,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9472879,
     "sourceId": 14813774,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 227.869115,
   "end_time": "2026-02-12T14:31:34.701585",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-12T14:27:46.832470",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
